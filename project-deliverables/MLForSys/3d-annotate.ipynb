{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"ball2_soft\"\n",
    "output_base_dir = os.path.join(base_dir, \"output\")\n",
    "image_dir = os.path.join(base_dir, \"IMAGE\")\n",
    "depth_dir = os.path.join(base_dir, \"DEPTH\")\n",
    "visualize = False\n",
    "\n",
    "if not os.path.exists(output_base_dir):\n",
    "    os.makedirs(output_base_dir)\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "if not os.path.exists(depth_dir):\n",
    "    os.makedirs(depth_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize directory\n",
    "filenames = sorted(os.listdir(base_dir))\n",
    "\n",
    "for f in filenames:\n",
    "    if \"depth\" in f:\n",
    "        os.rename(os.path.join(base_dir, f), os.path.join(depth_dir, f))\n",
    "    elif \"left\" in f:\n",
    "        os.rename(os.path.join(base_dir, f), os.path.join(image_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {}\n",
    "find_manually = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [01:03,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(image_dir)\n",
    "for idx, image_path in tqdm(enumerate(images)):\n",
    "    full_image_path = os.path.join(image_dir, image_path)\n",
    "    image2 = cv2.imread(full_image_path)\n",
    "    image = Image.open(full_image_path).convert(\"RGB\")\n",
    "\n",
    "    # you can specify the revision tag if you don't want the timm dependency\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # convert outputs (bounding boxes and class logits) to COCO API\n",
    "    # let's only keep detections with score > 0.9\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.1)[0]\n",
    "\n",
    "    temp_box = None\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        if model.config.id2label[label.item()] == \"orange\" or model.config.id2label[label.item()] == \"sports ball\":\n",
    "            temp_box = box\n",
    "            annotations[image_path] = box\n",
    "            # image2 = cv2.rectangle(image2, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), 2)\n",
    "            # plt.imshow(image2,cmap='gray')\n",
    "            # plt.show()\n",
    "            \n",
    "    if temp_box == None:\n",
    "        find_manually.append(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_annotations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/3d_annotator/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:782\u001b[0m, in \u001b[0;36mWidget._handle_msg\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 782\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_custom_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbuffers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# Catch remainder.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown front-end to back-end widget msg with method \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m method)\n",
      "File \u001b[0;32m~/.conda/envs/3d_annotator/lib/python3.10/site-packages/jupyter_bbox_widget/bbox.py:100\u001b[0m, in \u001b[0;36mBBoxWidget._handle_custom_msg\u001b[0;34m(self, content, buffers)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit_callback:\n\u001b[0;32m--> 100\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_callback:\n",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36msubmit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m manual_annotations[image_file] \u001b[38;5;241m=\u001b[39m w_bbox\u001b[38;5;241m.\u001b[39mbboxes\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# with open(\"full_annotations.json\", 'w') as f:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     json.dump(manual_annotations, f, indent=4)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# move on to the next file\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mskip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36mskip\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m w_progress\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# open new image in the widget\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m image_file \u001b[38;5;241m=\u001b[39m \u001b[43mfind_manually\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m w_bbox\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, image_file)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# here we assign an empty list to bboxes but \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# we could also run a detection model on the file\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# and use its output for creating inital bboxes\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# a progress bar to show how far we got\n",
    "w_progress = widgets.IntProgress(value=0, max=len(find_manually), description='Progress')\n",
    "# the bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image = os.path.join(image_dir, find_manually[0])\n",
    ")\n",
    "\n",
    "# combine widgets into a container\n",
    "w_container = widgets.VBox([\n",
    "    w_progress,\n",
    "    w_bbox,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when Skip button is pressed we move on to the next file\n",
    "@w_bbox.on_skip\n",
    "def skip():\n",
    "    w_progress.value += 1\n",
    "    # open new image in the widget\n",
    "    image_file = find_manually[w_progress.value]\n",
    "    w_bbox.image = os.path.join(image_dir, image_file)\n",
    "    # here we assign an empty list to bboxes but \n",
    "    # we could also run a detection model on the file\n",
    "    # and use its output for creating inital bboxes\n",
    "    w_bbox.bboxes = [] \n",
    "    if image_file not in manual_annotations:\n",
    "        manual_annotations[image_file] = w_bbox.bboxes\n",
    "\n",
    "# when Submit button is pressed we save current annotations\n",
    "# and then move on to the next file\n",
    "@w_bbox.on_submit\n",
    "def submit():\n",
    "    image_file = find_manually[w_progress.value]\n",
    "    # save annotations for current image\n",
    "    manual_annotations[image_file] = w_bbox.bboxes\n",
    "    # with open(\"full_annotations.json\", 'w') as f:\n",
    "    #     json.dump(manual_annotations, f, indent=4)\n",
    "    # move on to the next file\n",
    "    skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2d1b61b9e34792950e833551521688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, description='Progress', max=1), BBoxWidget(colors=['#1f77b4', '#ff7f0e', '…"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_manual_annotations = {}\n",
    "for key in manual_annotations:\n",
    "    data = manual_annotations[key]\n",
    "    if len(data) == 0:\n",
    "        val = []\n",
    "    else:\n",
    "        data = data[0]\n",
    "        val = [data['x'], data['y'], data['x'] + data['width'], data['y'] + data['height']]\n",
    "    edited_manual_annotations[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_annotations = edited_manual_annotations | annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_base_dir, f\"{base_dir}_full_annotations.json\"), \"w\") as f:\n",
    "    json.dump(full_annotations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  7.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def draw_center_on_image(image_path, json_data, output_dir):\n",
    "    # Load the image from the given path\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Extract the filename from the image path (assumes the image path includes the filename)\n",
    "    filename = os.path.basename(image_path)\n",
    "    \n",
    "    # Check if the filename is in the JSON data\n",
    "    if filename in json_data and len(json_data[filename]) > 0:\n",
    "        \n",
    "        # Get the bounding box coordinates from the JSON data\n",
    "        x1, y1, x2, y2 = json_data[filename]\n",
    "        \n",
    "        # Calculate the center of the bounding box\n",
    "        center_x = int((x1 + x2) // 2)\n",
    "        center_y = int((y1 + y2) // 2)\n",
    "        \n",
    "        # Draw a red dot (center) on the image\n",
    "        cv2.circle(image, (center_x, center_y), 5, (0, 0, 255), -1)  # Red circle with radius 5\n",
    "        \n",
    "        \n",
    "        # Save the modified image to the output directory\n",
    "        output_image_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "    else:\n",
    "        print(f\"Bounding box not found for {filename} in the JSON data.\")\n",
    "\n",
    "# Example usage:\n",
    "image_dir = os.path.join(base_dir, \"IMAGE\")  # Path to the input image\n",
    "json_file = os.path.join(output_base_dir, f\"{base_dir}_full_annotations.json\")  # Path to the JSON file with bounding boxes\n",
    "if visualize:\n",
    "    output_dir = os.path.join(base_dir, f\"{base_dir}_VIS_ANN\")  # Directory to save the modified images\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # Load the JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        bounding_boxes = json.load(f)\n",
    "\n",
    "    # Call the function to process the image\n",
    "    for image_path in tqdm(os.listdir(image_dir)):\n",
    "        image_path = os.path.join(image_dir, image_path)\n",
    "        draw_center_on_image(image_path, bounding_boxes, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "def cvt(key):\n",
    "    match = re.match(r\"left(\\d+).png\", key)\n",
    "    if match:\n",
    "        # Convert the matched string to an integer and return\n",
    "        return int(match.group(1))\n",
    "    return -1\n",
    "\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "new_data = {}\n",
    "\n",
    "for key in sorted(data.keys()):\n",
    "    new_key = int(cvt(key))\n",
    "    new_data[new_key] = data[key]\n",
    "    \n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(new_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_annotator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
